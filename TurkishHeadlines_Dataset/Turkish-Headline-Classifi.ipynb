{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4b1f74c",
   "metadata": {},
   "source": [
    "# About Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10405d9",
   "metadata": {},
   "source": [
    "\n",
    "Dataset consists of 7 news type labels. These labels are economy, politics, life, technology, magazine, health, sport. This dataset was created by me via Mynet, Milliyet, etc websites.\n",
    "There are 600 headlines for each label in the dataset . Hence, total headlines count is 4200 for dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e163b6",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a78f74c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HABERLER</th>\n",
       "      <th>ETIKET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TÜİK verilerine göre sanayi ciro endeksi Ağust...</td>\n",
       "      <td>Ekonomi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Piyasa güne eksi rezervde başladı</td>\n",
       "      <td>Ekonomi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Citigroup, Deutsche Bank ve HSBC Libor manipül...</td>\n",
       "      <td>Ekonomi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gelişen piyasa yatırımcılarını en fazla 'Fed' ...</td>\n",
       "      <td>Ekonomi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bitcoin fiyatında yükseliş hız kesmiyor</td>\n",
       "      <td>Ekonomi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            HABERLER   ETIKET\n",
       "0  TÜİK verilerine göre sanayi ciro endeksi Ağust...  Ekonomi\n",
       "1                  Piyasa güne eksi rezervde başladı  Ekonomi\n",
       "2  Citigroup, Deutsche Bank ve HSBC Libor manipül...  Ekonomi\n",
       "3  Gelişen piyasa yatırımcılarını en fazla 'Fed' ...  Ekonomi\n",
       "4            Bitcoin fiyatında yükseliş hız kesmiyor  Ekonomi"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv(\"Turkish-HeadLines.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f4e0d1",
   "metadata": {},
   "source": [
    "As we can see data we have contains only strings, and making classification with strings we need catch string similarities. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54334992",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5ac21b",
   "metadata": {},
   "source": [
    "# Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8221a2e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['TÜİK verilerine göre sanayi ciro endeksi Ağustos ayında bir önceki yılın aynı ayına göre %26,6 arttı.',\n",
       "       'Piyasa güne eksi rezervde başladı',\n",
       "       'Citigroup, Deutsche Bank ve HSBC Libor manipülasyonu davasında 132 milyon dolar ödemeyi kabul ettiler.',\n",
       "       ...,\n",
       "       'Konak ilçesindeki operasyonda 55 gram esrar, 55 uyuşturucu hap ile 1 ruhsatsız tabanca ele geçirildi, 1 kişi tutuklandı',\n",
       "       \"Siirt ve Manisa'da düzenlenen operasyonda gözaltına alınan eski 2 kaymakam ve savcı tutuklandı\",\n",
       "       \"Denizli'de Kaçak Sigara Operasyonu: 13 Gözaltı\"], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = data[:,0]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f421bebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ekonomi', 'Ekonomi', 'Ekonomi', ..., 'Yaşam', 'Yaşam', 'Yaşam'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_data = data[:,-1]\n",
    "target_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8017e6a2",
   "metadata": {},
   "source": [
    "# Changing target data string to integer value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4274516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ekonomi', 'Magazin', 'Sağlık', 'Siyaset', 'Spor', 'Teknoloji', 'Yaşam'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_set = {s for s in target_data}\n",
    "target_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32fdec76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Teknoloji': 0,\n",
       " 'Ekonomi': 1,\n",
       " 'Spor': 2,\n",
       " 'Sağlık': 3,\n",
       " 'Magazin': 4,\n",
       " 'Yaşam': 5,\n",
       " 'Siyaset': 6}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_id = {}\n",
    "i=0\n",
    "for s in target_set:\n",
    "    target_id[s] = i\n",
    "    i+=1\n",
    "target_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2448fc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [target_id[s] for s in target_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e9f7c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %25 test %75 train\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=37, stratify=y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffbeebd",
   "metadata": {},
   "source": [
    "# Tokenizing text\n",
    "Text preprocessing, tokenizing and filtering of stopwords are all included in CountVectorizer, which builds a dictionary of features and transforms documents to feature vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a785b07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3150, 13044)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "x_train_counts = count_vect.fit_transform(x_train)\n",
    "x_train_counts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46508157",
   "metadata": {},
   "source": [
    "# From occurrences to frequencies\n",
    "\n",
    "Occurrence count is a good start but there is an issue: longer documents will have higher average count values than shorter documents, even though they might talk about the same topics.\n",
    "\n",
    "To avoid these potential discrepancies it suffices to divide the number of occurrences of each word in a document by the total number of words in the document: these new features are called tf for Term Frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49011788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3150, 13044)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tf_transformer = TfidfTransformer(use_idf=False).fit(x_train_counts)\n",
    "x_train_tf = tf_transformer.transform(x_train_counts)\n",
    "x_train_tf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c973f10",
   "metadata": {},
   "source": [
    "Another refinement on top of tf is to downscale weights for words that occur in many documents in the corpus and are therefore less informative than those that occur only in a smaller portion of the corpus.\n",
    "\n",
    "This downscaling is called tf–idf for “Term Frequency times Inverse Document Frequency”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0245e7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3150, 13044)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "x_train_tfidf = tfidf_transformer.fit_transform(x_train_counts)\n",
    "x_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b004635",
   "metadata": {},
   "source": [
    "# Starting with Naive Algo\n",
    "Let’s start with a naive Bayes classifier, which provides a nice baseline for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7e7606a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(x_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727c4771",
   "metadata": {},
   "source": [
    "Let's see how that works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c5653d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_test_data = np.array([\"Altın fiyatlarında Artış!\", \"Olimpiyatlarda Sporcumuz Gümüş Madalya Aldı\"])\n",
    "ex_test_data = ex_test_data.astype('object')\n",
    "x_new_counts = count_vect.transform(ex_test_data)\n",
    "x_new_tfidf = tfidf_transformer.transform(x_new_counts)\n",
    "predicted = clf.predict(x_new_tfidf)\n",
    "predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d86307",
   "metadata": {},
   "source": [
    "Getting the Headlines from id dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea2e848b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ekonomi\n",
      "Spor\n"
     ]
    }
   ],
   "source": [
    "def get_key(val):\n",
    "    for key, value in target_id.items():\n",
    "         if val == value:\n",
    "             return key\n",
    "for i in predicted:\n",
    "    print(get_key(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449942e0",
   "metadata": {},
   "source": [
    "Works pretty good."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5eb91b4",
   "metadata": {},
   "source": [
    "# Using Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f615598e",
   "metadata": {},
   "source": [
    "\n",
    "In order to make the vectorizer => transformer => classifier easier to work with, scikit-learn provides a Pipeline class that behaves like a compound classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c235727a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "     ('tfidf', TfidfTransformer()),\n",
    "     ('clf', MultinomialNB()),\n",
    " ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "208d30fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf.fit(x_train, y_train)\n",
    "y_pred_naive = text_clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c8e4b5",
   "metadata": {},
   "source": [
    "# Evaluation of the performance on the test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd7aa70d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred_naive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c81e121",
   "metadata": {},
   "source": [
    "We achieved 96.7% accuracy which is great performance by naive algo. Let’s see if we can do better with a linear support vector machine (SVM), which is widely regarded as one of the best text classification algorithms (although it’s also a bit slower than naïve Bayes). We can change the learner by simply plugging a different classifier object into our pipeline:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8c72ab",
   "metadata": {},
   "source": [
    "# Continue SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1fba24db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "     ('tfidf', TfidfTransformer()),\n",
    "     ('clf', SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, random_state=37, max_iter=5, tol=None)),\n",
    " ])\n",
    "text_clf.fit(x_train, y_train)\n",
    "y_pred_SVM = text_clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bafdeb14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9657142857142857"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred_SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6c7b52",
   "metadata": {},
   "source": [
    "We achieved 96.6% accuracy. Let's get detailed info about our performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "035f8ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Teknoloji       0.97      0.93      0.95       150\n",
      "     Ekonomi       0.99      0.93      0.96       150\n",
      "        Spor       0.99      0.99      0.99       150\n",
      "      Sağlık       0.92      0.97      0.94       150\n",
      "     Magazin       0.99      0.97      0.98       150\n",
      "       Yaşam       0.98      0.98      0.98       150\n",
      "     Siyaset       0.94      0.99      0.96       150\n",
      "\n",
      "    accuracy                           0.97      1050\n",
      "   macro avg       0.97      0.97      0.97      1050\n",
      "weighted avg       0.97      0.97      0.97      1050\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test, y_pred_SVM, target_names=target_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0686cae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[139,   1,   1,   7,   0,   1,   1],\n",
       "       [  2, 140,   0,   2,   1,   0,   5],\n",
       "       [  0,   0, 149,   0,   0,   1,   0],\n",
       "       [  1,   1,   0, 145,   0,   0,   3],\n",
       "       [  1,   0,   0,   2, 146,   1,   0],\n",
       "       [  0,   0,   0,   2,   1, 147,   0],\n",
       "       [  1,   0,   1,   0,   0,   0, 148]], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, y_pred_SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc95cff",
   "metadata": {},
   "source": [
    "# Confusion Values\n",
    "Let's see what went wrong with 2.5% wrong decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "afdf9259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TBMM Sağlık Komisyonu Başkanı Kavuncu, \"Elektronik sigaranın içindeki nikotin de en az sigara kadar zararlı. Gençlerimizin buna aldanmaması gerekir\" uyarısında bulundu\n",
      "Predicted Class:Siyaset\n",
      "Right Class:Sağlık\n",
      "\n",
      "Bankaların Birleşme, Devir, Bölünme ve Hisse Değişimi Hakkında Yönetmeliği yeniden düzenlendi.\n",
      "Predicted Class:Sağlık\n",
      "Right Class:Ekonomi\n",
      "\n",
      "Eylem Gülçin Kanık Cinayetindeki Gelişmeler Kan Dondurdu\n",
      "Predicted Class:Sağlık\n",
      "Right Class:Yaşam\n",
      "\n",
      "Bitcoinin %1'ine sahip milyarder ikizler\n",
      "Predicted Class:Teknoloji\n",
      "Right Class:Ekonomi\n",
      "\n",
      " dünyayı etkisine alan ve 150 ülkede 200 binden fazla bilgisayara bulaşan WannaCry virüsü, dikkat edilmesi gereken ve mutlaka önlem alınması gereken bir zararlı yazılım.\n",
      "Predicted Class:Sağlık\n",
      "Right Class:Teknoloji\n",
      "\n",
      "Ünlü Türk markasının Bitcoin planı\n",
      "Predicted Class:Magazin\n",
      "Right Class:Ekonomi\n",
      "\n",
      "General Mobile GM 6 dayanıklılık testi videomuda, elimizde olan 2 tane GM 6 modelini şut bombardımanına tuttuk ve ne kadar dayanıklı olduğunu gözlemledik.\n",
      "Predicted Class:Sağlık\n",
      "Right Class:Teknoloji\n",
      "\n",
      "Dallas Fed Başkanı Robert Kaplan, ekonominin tam istihdama yakın olduğunu söyledi.\n",
      "Predicted Class:Siyaset\n",
      "Right Class:Ekonomi\n",
      "\n",
      "TÜYAP'ta düzenlenen kitap fuarında Olimpos yayınevi standında 'Sendeki Ben' isimli kitabının imza günü için sevenleriyle bir arayagelen Leyla Bilginel'i, 17 yaşındaki bir genç hayranı ağlattı.\n",
      "Predicted Class:Yaşam\n",
      "Right Class:Magazin\n",
      "\n",
      "Programlanabilir metal elektromanyetik alanla kontrol edilerek şekil değiştirebiliyor. Programlanabilir sıvı metal elektroniğin geleceği olabilecek potansiyelde.\n",
      "Predicted Class:Sağlık\n",
      "Right Class:Teknoloji\n",
      "\n",
      "Piyasalarda Trump-Şi Cinping görüşmesi takip ediliyor\n",
      "Predicted Class:Siyaset\n",
      "Right Class:Ekonomi\n",
      "\n",
      "SSK'lı çalışan işçilere kıdem tazminatı konusunda yeni yıldan itibaren zam yapılacak.\n",
      "Predicted Class:Teknoloji\n",
      "Right Class:Ekonomi\n",
      "\n",
      "Ünlüler arasında göğüs, bel ve kalça ölçülerinin birbirine oranı kusursuza en yakın isim 32 yaşındaki Danimarka asıllı Amerikalı aktris Scarlett Johansson oldu. \n",
      "Predicted Class:Sağlık\n",
      "Right Class:Magazin\n",
      "\n",
      "Arakan'da Myanmar ordusu ve Budistler katlettikleri Müslümanları arkalarında delil bırakmamak için yakıyor.\n",
      "Predicted Class:Sağlık\n",
      "Right Class:Yaşam\n",
      "\n",
      "Kronik bel ağrılarının yüzde 40'ından faset sendromu sorumlu\n",
      "Predicted Class:Ekonomi\n",
      "Right Class:Sağlık\n",
      "\n",
      "Uzun süredir sahne ve ekranlardan uzak kalan Özlem Savaş, imaj yeniledi.\n",
      "Predicted Class:Sağlık\n",
      "Right Class:Magazin\n",
      "\n",
      "Stok siteleri filigran önlemi almaya başladı!\n",
      "Predicted Class:Ekonomi\n",
      "Right Class:Teknoloji\n",
      "\n",
      "Aktris Natalie Portman, Forbes dergisinin Hollywoodun en çok gelire sahip yıldızları listesinde ilk 10a giren kişilerin başında geldi.\n",
      "Predicted Class:Teknoloji\n",
      "Right Class:Magazin\n",
      "\n",
      "Autodesk Yazılımlarına Ulaşma Şekli Değişiyor\n",
      "Predicted Class:Sağlık\n",
      "Right Class:Teknoloji\n",
      "\n",
      "İran Petrol Bakanı Rüstem Kasımi, Batı'nın ülkesine yönelik yaptırımları daha da ağırlaştırması halinde petrol ihracatını gözden geçireceklerini belirtti.\n",
      "Predicted Class:Siyaset\n",
      "Right Class:Ekonomi\n",
      "\n",
      "Vestel, dünya çapında birçok markanın yarıştığı Plus X Award'da yılın en yenilikçi markası seçildi.\n",
      "Predicted Class:Spor\n",
      "Right Class:Teknoloji\n",
      "\n",
      "Kritik MGK toplandı. Milli Güvenlik Kurulu'nda OHAL'in 3 ay daha uzatılması ile İdlib operasyonu ve Kerkük'te yaşanan gelişmeler ele alınacak.\n",
      "Predicted Class:Spor\n",
      "Right Class:Siyaset\n",
      "\n",
      "Save The Children, 2015'ten bu yana iç savaşın sürdüğü Yemen'de her gün yaklaşık 130 çocuğun öldüğünü açıkladı.\n",
      "Predicted Class:Magazin\n",
      "Right Class:Yaşam\n",
      "\n",
      "Isı bataryası, güneş enerjisinin depolanması veya atık ısıların geri kazanılması konusunda oldukça önemli bir araç.\n",
      "Predicted Class:Sağlık\n",
      "Right Class:Teknoloji\n",
      "\n",
      "NVIDIA PC Gaming Revival Kit, içeriğindeki bilgisayarınızı diriltecek üçüncü parti üretici donanımlarıyla dikkat çekmeyi başarıyor.\n",
      "Predicted Class:Siyaset\n",
      "Right Class:Teknoloji\n",
      "\n",
      "İnternetten “kitle fonlama” mevzuata giriyor. Melek yatırımcı, internet platformlarından fon bulabilecek.\n",
      "Predicted Class:Sağlık\n",
      "Right Class:Ekonomi\n",
      "\n",
      "Fidye virüsleri son birkaç yıl içerisinde çok büyük miktarlarda mali zarara neden oldu.\n",
      "Predicted Class:Sağlık\n",
      "Right Class:Teknoloji\n",
      "\n",
      "Türkiye Sermaye Piyasaları Kongresi'ne katılan Sermaye Piyasası Kurulu (SPK) Başkanı Vahdettin Ertaş ve Borsa İstanbul Yönetim Kurulu Başkanı Himmet Karadağ birbirinden önemli açıklamalarda bulundu.\n",
      "Predicted Class:Siyaset\n",
      "Right Class:Ekonomi\n",
      "\n",
      "Cinsellikle ilgili beklentiler değişiklik gösteriyor\n",
      "Predicted Class:Siyaset\n",
      "Right Class:Sağlık\n",
      "\n",
      "Ekonomi Bakanı Zeybekci, yeni düzenlemeyle yurt dışından marka satın alan firmalara 2 milyon dolara kadar destek vereceklerini söyledi.\n",
      "Predicted Class:Siyaset\n",
      "Right Class:Ekonomi\n",
      "\n",
      "Symantec, 1 Ocak 2009 ve 31 Aralık 2009 tarihleri arasında, internet tehditleri açısından kullanıcılar üzerinde etkili olan önemli siber suç trendlerini vurguladığı XV. Internet Güvenliği Tehditleri Raporu‘nu yayınladı.\n",
      "Predicted Class:Sağlık\n",
      "Right Class:Teknoloji\n",
      "\n",
      "Times gazetesinin haberine göre, Polonya Sağlık Bakanlığı'nın düşen nüfus oranlarını arttırmak için hazırlattığı eğitim videosunda çiftlere \"tavşanlar gibi sevişin\" mesajı verildi.\n",
      "Predicted Class:Siyaset\n",
      "Right Class:Sağlık\n",
      "\n",
      "İnternet üzerindeki en büyük tehlike olarak betimlenen hackerların bu seferki saldırı adresleri porno siteleri oldu.\n",
      "Predicted Class:Yaşam\n",
      "Right Class:Teknoloji\n",
      "\n",
      "Uzun süre tokluk hissi yaratan, çabuk acıkmanızı engelleyen 10 besini şöyle sıralayabiliriz...\n",
      "Predicted Class:Teknoloji\n",
      "Right Class:Sağlık\n",
      "\n",
      "Çağlar Söyüncü Freiburg'da, Cengiz Ünder Roma'da... Türk futbolunun genç yetenek fabrikası Altınordu'da şimdi de 17 yaşındaki kaleci Berke Özer, Avrupa yolunda...\n",
      "Predicted Class:Yaşam\n",
      "Right Class:Spor\n",
      "\n",
      "İtalya'da yeni hükümeti kuran Paolo Gentiloni, selefi Matteo Renzi'den başbakanlık görevini resmen devraldı.\n",
      "Predicted Class:Teknoloji\n",
      "Right Class:Siyaset\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(y_test)):\n",
    "    right_class = y_test[i]\n",
    "    predicted_class = y_pred_SVM[i]\n",
    "    if (right_class != predicted_class):\n",
    "        print(x_test[i]+ \"\\nPredicted Class:\" + get_key(predicted_class))\n",
    "        print(\"Right Class:\" + get_key(right_class) + \"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
